{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# --- Training Data Configuration ---\n",
        "# Set this flag to control the data used for training:\n",
        "# 1: Use all available historical data before 2025\n",
        "# 2: Use data from 2000 to 2024\n",
        "# 3: Use data from 2020 to 2024\n",
        "TRAINING_DATA_RANGE = 2\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "# Assuming the file 'f1_main_table_canada_full.csv' is in the same directory\n",
        "try:\n",
        "    # Using low_memory=False to avoid DtypeWarning\n",
        "    df_full = pd.read_csv('f1_main_table_canada_full.csv', sep=';', low_memory=False)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'f1_main_table_canada_full.csv' not found. Please ensure the file is in the correct directory.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CSV: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 2. Preprocess Data ---\n",
        "# Select relevant columns\n",
        "relevant_cols = [\n",
        "    'year', 'round', 'circuitRef', 'driverRef', 'constructorRef',\n",
        "    'race_grid', 'race_position', 'qualy_position', 'statusId'\n",
        "]\n",
        "df = df_full[relevant_cols].copy()\n",
        "\n",
        "# Filter for Canadian GP (Circuit Gilles Villeneuve)\n",
        "df = df[df['circuitRef'] == 'villeneuve'].copy()\n",
        "if df.empty:\n",
        "    print(\"Error: No data found for circuitRef 'villeneuve' (Canadian GP).\")\n",
        "    exit()\n",
        "\n",
        "# Convert columns to numeric, coercing errors\n",
        "numeric_cols = ['race_grid', 'race_position', 'qualy_position', 'year', 'round']\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Handle missing crucial values\n",
        "df.dropna(subset=['race_grid', 'race_position', 'qualy_position', 'driverRef', 'constructorRef', 'year'], inplace=True)\n",
        "\n",
        "# Create target variable: is_winner (1 if race_position is 1, 0 otherwise)\n",
        "df['is_winner'] = np.where(df['race_position'] == 1, 1, 0)\n",
        "\n",
        "# Ensure year is an integer for easier filtering\n",
        "df['year'] = df['year'].astype(int)\n",
        "\n",
        "# --- 3. Feature Engineering & Encoding ---\n",
        "features = ['year', 'round', 'driverRef', 'constructorRef', 'race_grid', 'qualy_position']\n",
        "categorical_features = ['driverRef', 'constructorRef']\n",
        "\n",
        "# Convert categorical features to 'category' dtype for LightGBM\n",
        "# Store categories for consistent encoding in prediction data\n",
        "category_mappings = {}\n",
        "for col in categorical_features:\n",
        "    df[col] = df[col].astype('category')\n",
        "    category_mappings[col] = dict(enumerate(df[col].cat.categories))\n",
        "    df[col + '_code'] = df[col].cat.codes # Use codes for training\n",
        "\n",
        "# Update features list to use encoded columns\n",
        "encoded_features = ['year', 'round', 'driverRef_code', 'constructorRef_code', 'race_grid', 'qualy_position']\n",
        "X = df[encoded_features]\n",
        "y = df['is_winner']\n",
        "\n",
        "# --- 4. Train LightGBM Model ---\n",
        "# Select data based on TRAINING_DATA_RANGE flag\n",
        "if TRAINING_DATA_RANGE == 1:\n",
        "    X_train = X[df['year'] < 2025]\n",
        "    y_train = y[df['year'] < 2025]\n",
        "    print(\"\\nTraining on all historical data before 2025.\")\n",
        "elif TRAINING_DATA_RANGE == 2:\n",
        "    X_train = X[(df['year'] >= 2000) & (df['year'] < 2025)]\n",
        "    y_train = y[(df['year'] >= 2000) & (df['year'] < 2025)]\n",
        "    print(\"\\nTraining on data from 2000 to 2024.\")\n",
        "elif TRAINING_DATA_RANGE == 3:\n",
        "    X_train = X[(df['year'] >= 2020) & (df['year'] < 2025)]\n",
        "    y_train = y[(df['year'] >= 2020) & (df['year'] < 2025)]\n",
        "    print(\"\\nTraining on data from 2024 only.\")\n",
        "else:\n",
        "    print(\"\\nInvalid TRAINING_DATA_RANGE specified. Please use 1, 2, or 3.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "if X_train.empty:\n",
        "    print(\"Error: No training data available for the selected range.\")\n",
        "    print(\"Please check the 'f1_main_table_canada_full.csv' file and the TRAINING_DATA_RANGE setting.\")\n",
        "    exit()\n",
        "\n",
        "# LightGBM Classifier\n",
        "lgbm_model = lgb.LGBMClassifier(random_state=42, force_col_wise=True)\n",
        "try:\n",
        "    lgbm_model.fit(X_train, y_train, categorical_feature=['driverRef_code', 'constructorRef_code'])\n",
        "    print(f\"Model trained successfully on {len(X_train)} samples.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during model training: {e}\")\n",
        "    print(\"This can happen if categorical features have issues or data is too sparse for the selected training range.\")\n",
        "    exit()\n",
        "\n",
        "# --- 5. Prepare 2025 Scenario Data ---\n",
        "# Helper function to get the category code for a value - Not strictly needed anymore with astype(pd.CategoricalDtype)\n",
        "# def get_code(value, col_name, mappings):\n",
        "#     for code, cat_val in mappings[col_name].items():\n",
        "#         if cat_val == value:\n",
        "#             return code\n",
        "#     return -1 # Or handle as unknown, LightGBM might need specific handling for this\n",
        "\n",
        "# Helper function to find the most recent constructor for a driver\n",
        "def get_latest_constructor(driver_ref, historical_df):\n",
        "    # Use data before 2025 for the most recent constructor\n",
        "    driver_data = historical_df[\n",
        "        (historical_df['driverRef'] == driver_ref) & (historical_df['year'] < 2025)\n",
        "    ].sort_values(by=['year', 'round'], ascending=[False, False])\n",
        "    if not driver_data.empty:\n",
        "        return driver_data.iloc[0]['constructorRef']\n",
        "    return None # Fallback if driver not found or no constructor data before 2025\n",
        "\n",
        "# Define drivers for scenarios\n",
        "drivers_scenarios = {\n",
        "    \"VER\": \"max_verstappen\",\n",
        "    \"NOR\": \"norris\",\n",
        "    \"HAM\": \"hamilton\"\n",
        "}\n",
        "\n",
        "predictions_2025 = {}\n",
        "\n",
        "print(\"\\n--- Predicting for 2025 Canadian GP ---\")\n",
        "\n",
        "for driver_short_name, driver_full_ref in drivers_scenarios.items():\n",
        "    print(f\"\\nScenario for {driver_short_name} ({driver_full_ref}):\")\n",
        "\n",
        "    # Check if driver existed in the *full* historical data categories\n",
        "    if driver_full_ref not in category_mappings['driverRef'].values():\n",
        "        print(f\"  Driver '{driver_full_ref}' not found in full historical data categories. Cannot make prediction.\")\n",
        "        predictions_2025[driver_short_name] = \"N/A (Driver not in full historical data)\"\n",
        "        continue\n",
        "\n",
        "    # Demo values for 2025\n",
        "    # Use the full dataset before 2025 to find the latest constructor, regardless of the TRAINING_DATA_RANGE\n",
        "    latest_constructor = get_latest_constructor(driver_full_ref, df_full[relevant_cols].copy())\n",
        "    if latest_constructor is None:\n",
        "        print(f\"  Could not determine latest constructor for {driver_full_ref} from historical data before 2025. Using a placeholder 'unknown_constructor'.\")\n",
        "        latest_constructor = 'unknown_constructor'\n",
        "\n",
        "    # Check if the assumed constructor was in the *full* historical data categories\n",
        "    if latest_constructor not in category_mappings['constructorRef'].values() and latest_constructor != 'unknown_constructor':\n",
        "         print(f\"  Constructor '{latest_constructor}' for {driver_full_ref} was not in the full historical training data categories. Prediction might be unreliable or impossible depending on model handling of unseen categories.\")\n",
        "         # LightGBM handles unseen categories based on its configuration (e.g., zero_as_missing)\n",
        "         # If 'unknown_constructor' is used and wasn't a category, it will be treated as missing.\n",
        "         # If a known constructor from before 2025 is new to the training subset, LightGBM will treat it as unknown if its code is -1.\n",
        "\n",
        "    scenario_data = {\n",
        "        'year': [2025],\n",
        "        'round': [10], # Hypothetical round number for Canadian GP in 2025\n",
        "        'driverRef': [driver_full_ref],\n",
        "        'constructorRef': [latest_constructor],\n",
        "        'race_grid': [1], # Hypothetical: Driver starts P1\n",
        "        'qualy_position': [1] # Hypothetical: Driver qualifies P1\n",
        "    }\n",
        "    scenario_df = pd.DataFrame(scenario_data)\n",
        "\n",
        "    # Encode categorical features for the scenario using the *full* historical categories\n",
        "    try:\n",
        "        # Use the categories learned from the full dataset for consistent encoding\n",
        "        scenario_df['driverRef_code'] = scenario_df['driverRef'].astype(pd.CategoricalDtype(categories=category_mappings['driverRef'].values())).cat.codes\n",
        "        scenario_df['constructorRef_code'] = scenario_df['constructorRef'].astype(pd.CategoricalDtype(categories=category_mappings['constructorRef'].values())).cat.codes\n",
        "\n",
        "        # Check if any codes are -1 (unknown category relative to the full historical data)\n",
        "        if scenario_df['driverRef_code'].iloc[0] == -1:\n",
        "            print(f\"  Warning: Driver '{driver_full_ref}' was not in the full original historical categories after mapping. Prediction may be inaccurate.\")\n",
        "        if scenario_df['constructorRef_code'].iloc[0] == -1:\n",
        "             print(f\"  Warning: Constructor '{latest_constructor}' was not in the full original historical categories after mapping. Prediction may be inaccurate.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  Error encoding scenario data for {driver_full_ref}: {e}\")\n",
        "        predictions_2025[driver_short_name] = f\"N/A (Encoding error: {e})\"\n",
        "        continue\n",
        "\n",
        "    # Select features for prediction - ensure order and names match training data\n",
        "    X_scenario = scenario_df[encoded_features]\n",
        "\n",
        "    # --- 6. Make Predictions ---\n",
        "    try:\n",
        "        # predict_proba returns probabilities for both classes (0 and 1).\n",
        "        # We want the probability of winning, which is the probability of class 1.\n",
        "        win_probability = lgbm_model.predict_proba(X_scenario)[:, 1]\n",
        "        predictions_2025[driver_short_name] = f\"{win_probability[0]*100:.2f}%\"\n",
        "        print(f\"  Assumed Constructor for 2025: {latest_constructor}\")\n",
        "        print(f\"  Assumed Starting Grid: P1\")\n",
        "        print(f\"  Assumed Qualifying position: P1\")\n",
        "        print(f\"  Predicted Win Probability: {predictions_2025[driver_short_name]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  Error during prediction for {driver_full_ref}: {e}\")\n",
        "        predictions_2025[driver_short_name] = f\"N/A (Prediction error: {e})\"\n",
        "\n",
        "\n",
        "# --- 7. Output ---\n",
        "print(\"\\n--- Summary of 2025 Canadian GP Win Predictions (assuming P1 start) ---\")\n",
        "print(f\"Note: Model trained using TRAINING_DATA_RANGE = {TRAINING_DATA_RANGE}\")\n",
        "print(\"\\n1: Use all available historical data before 2025\")\n",
        "print(\"2: Use data from 2000 to 2024\")\n",
        "print(\"3: Use data from 2020 to 2024\\n\\n\")\n",
        "\n",
        "for driver_name, prob in predictions_2025.items():\n",
        "    # Use the full driver name from the dictionary\n",
        "    print(f\"  {drivers_scenarios[driver_name]}: {prob}\")\n",
        "\n",
        "print(\"\\n--- Explanation of Model Features ---\")\n",
        "print(\"The LightGBM model uses the following features to predict the probability of winning:\")\n",
        "print(f\"- **{encoded_features[0]}**: The year of the race.\")\n",
        "print(f\"- **{encoded_features[1]}**: The round number of the race within the season.\")\n",
        "print(f\"- **{encoded_features[2]}**: A numerical code representing the driver.\")\n",
        "print(f\"- **{encoded_features[3]}**: A numerical code representing the constructor (team).\")\n",
        "print(f\"- **{encoded_features[4]}**: The driver's starting position on the grid for the race.\")\n",
        "print(f\"- **{encoded_features[5]}**: The driver's qualifying position from the qualifying session.\")\n",
        "print(\"\\nNote: Categorical features (Driver and Constructor) are numerically encoded by pandas and LightGBM handles them efficiently.\")\n",
        "print(\"\\nDisclaimer:\")\n",
        "print(\"These predictions are based on historical data and the specific features used in the model.\")\n",
        "print(\"Actual race outcomes can be influenced by numerous factors not captured in this model (e.g., real-time car performance, strategy decisions, driver form fluctuations, race incidents, weather conditions, rule changes, etc.).\")\n",
        "print(\"The assumed constructor for 2025 is based on the driver's most recent team in the dataset prior to 2025.\")\n",
        "print(\"The prediction scenario assumes the driver starts and qualifies in P1 (first position).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BFYz3TyQ3jO",
        "outputId": "1e41e7a5-2254-437b-c84d-596d622c5d33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training on data from 2000 to 2024.\n",
            "[LightGBM] [Info] Number of positive: 2098, number of negative: 29604\n",
            "[LightGBM] [Info] Total Bins 189\n",
            "[LightGBM] [Info] Number of data points in the train set: 31702, number of used features: 6\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.066179 -> initscore=-2.646925\n",
            "[LightGBM] [Info] Start training from score -2.646925\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Model trained successfully on 31702 samples.\n",
            "\n",
            "--- Predicting for 2025 Canadian GP ---\n",
            "\n",
            "Scenario for VER (max_verstappen):\n",
            "  Assumed Constructor for 2025: red_bull\n",
            "  Assumed Starting Grid: P1\n",
            "  Assumed Qualifying position: P1\n",
            "  Predicted Win Probability: 94.47%\n",
            "\n",
            "Scenario for NOR (norris):\n",
            "  Assumed Constructor for 2025: mclaren\n",
            "  Assumed Starting Grid: P1\n",
            "  Assumed Qualifying position: P1\n",
            "  Predicted Win Probability: 0.01%\n",
            "\n",
            "Scenario for HAM (hamilton):\n",
            "  Assumed Constructor for 2025: mercedes\n",
            "  Assumed Starting Grid: P1\n",
            "  Assumed Qualifying position: P1\n",
            "  Predicted Win Probability: 94.47%\n",
            "\n",
            "--- Summary of 2025 Canadian GP Win Predictions (assuming P1 start) ---\n",
            "Note: Model trained using TRAINING_DATA_RANGE = 2\n",
            "\n",
            "1: Use all available historical data before 2025\n",
            "2: Use data from 2000 to 2024\n",
            "3: Use data from 2020 to 2024\n",
            "\n",
            "\n",
            "  max_verstappen: 94.47%\n",
            "  norris: 0.01%\n",
            "  hamilton: 94.47%\n",
            "\n",
            "--- Explanation of Model Features ---\n",
            "The LightGBM model uses the following features to predict the probability of winning:\n",
            "- **year**: The year of the race.\n",
            "- **round**: The round number of the race within the season.\n",
            "- **driverRef_code**: A numerical code representing the driver.\n",
            "- **constructorRef_code**: A numerical code representing the constructor (team).\n",
            "- **race_grid**: The driver's starting position on the grid for the race.\n",
            "- **qualy_position**: The driver's qualifying position from the qualifying session.\n",
            "\n",
            "Note: Categorical features (Driver and Constructor) are numerically encoded by pandas and LightGBM handles them efficiently.\n",
            "\n",
            "Disclaimer:\n",
            "These predictions are based on historical data and the specific features used in the model.\n",
            "Actual race outcomes can be influenced by numerous factors not captured in this model (e.g., real-time car performance, strategy decisions, driver form fluctuations, race incidents, weather conditions, rule changes, etc.).\n",
            "The assumed constructor for 2025 is based on the driver's most recent team in the dataset prior to 2025.\n",
            "The prediction scenario assumes the driver starts and qualifies in P1 (first position).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}